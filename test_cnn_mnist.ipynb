{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_contour_thresh(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    ret, thresh1 = cv2.threshold(blur, 70, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    return contours, thresh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = cv2.imread('test1.jpg')\n",
    "sample = cv2.cvtColor(sample, cv2.COLOR_RGB2GRAY)\n",
    "sample = cv2.resize(sample,(28,28))\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1000)\n",
    "cap.set(4, 600)\n",
    "x, y, w, h = 400, 240, 200, 200\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    frame = img[y:y+h, x:x+w]\n",
    "    contours, thresh = get_img_contour_thresh(frame)\n",
    "    ans1 = ''\n",
    "    if len(contours) > 0:\n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(contour) > 2500:\n",
    "            x1, y1, w1, h1 = cv2.boundingRect(contour)\n",
    "            newImage = thresh[y1:y1 + h1, x1:x1 + w1]\n",
    "            newImage = cv2.resize(newImage, (28, 28))\n",
    "            newImage = np.array(newImage)\n",
    "            newImage = newImage.flatten()\n",
    "            newImage = newImage.reshape(1, 28,28,1)\n",
    "            ans1 = model.predict_classes(newImage)\n",
    "            ans1 = ans1[0]\n",
    "    img = cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'Predicted:' + str(ans1),(50,50),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2) \n",
    "    cv2.imshow(\"Frame\", img)\n",
    "    cv2.imshow(\"Cropped\", frame)\n",
    "    cv2.imshow(\"Threshold\", thresh)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array(sample)\n",
    "sample = np.reshape(sample,(1,28,28,1))\n",
    "predicted = model.predict_classes(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
